{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ec3846",
   "metadata": {},
   "source": [
    "# ðŸ¥ Healthcare Data Integration & ETL Pipeline\n",
    "## HIPAA-Compliant Multi-Source Patient Data Warehouse\n",
    "\n",
    "**Project Overview:**\n",
    "Enterprise-grade ETL pipeline integrating patient data from Electronic Health Records (EHR), billing systems, and pharmacy data into a unified Snowflake data warehouse. Implements HIPAA compliance, data quality validation, and automated alerting.\n",
    "\n",
    "**Business Problem:**\n",
    "A regional healthcare network operates 15 hospitals with disparate systems:\n",
    "- Legacy EHR systems (Epic, Cerner)\n",
    "- Billing system (separate database)\n",
    "- Pharmacy management system\n",
    "- Patient portal data\n",
    "\n",
    "They need:\n",
    "1. Unified patient 360Â° view for care coordination\n",
    "2. Real-time readmission risk analytics\n",
    "3. HIPAA-compliant data handling\n",
    "4. Automated data quality monitoring\n",
    "5. Cost optimization and fraud detection\n",
    "\n",
    "**Technical Solution:**\n",
    "- **Extract:** AWS Glue jobs pulling from S3 (EHR exports), RDS (billing), API (pharmacy)\n",
    "- **Transform:** PySpark data cleansing, deduplication, PHI masking\n",
    "- **Load:** Incremental loads to Snowflake with SCD Type 2\n",
    "- **Orchestration:** AWS Step Functions + EventBridge\n",
    "- **Monitoring:** CloudWatch + SNS alerts\n",
    "- **BI Layer:** Power BI dashboards with row-level security\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Pamela Austin | Senior Data Analyst (Data Engineering)  \n",
    "**Date:** November 2025  \n",
    "**Technologies:** AWS Glue, PySpark, Snowflake, Python, SQL, HIPAA Compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1906b",
   "metadata": {},
   "source": [
    "## 1. Project Architecture & Setup\n",
    "\n",
    "### Data Sources:\n",
    "1. **EHR System (Epic)** - Daily full exports to S3 (CSV/Parquet)\n",
    "   - Patient demographics\n",
    "   - Encounters/visits\n",
    "   - Diagnoses (ICD-10)\n",
    "   - Procedures (CPT codes)\n",
    "   \n",
    "2. **Billing System** - RDS PostgreSQL\n",
    "   - Claims data\n",
    "   - Insurance information\n",
    "   - Payment history\n",
    "   \n",
    "3. **Pharmacy System** - REST API\n",
    "   - Prescription orders\n",
    "   - Medication dispensing\n",
    "   - Drug interactions\n",
    "\n",
    "### Target: Snowflake Data Warehouse\n",
    "- **Database:** HEALTHCARE_DW\n",
    "- **Schemas:** RAW, STAGING, CURATED, ANALYTICS\n",
    "- **Security:** Role-based access control (RBAC), data masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2152c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "import re\n",
    "from faker import Faker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# AWS SDK\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# PySpark imports (for Glue)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Snowflake connector\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "# Data quality\n",
    "from great_expectations.dataset import PandasDataset\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set styles\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Initialize Faker for generating synthetic healthcare data\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ðŸ“… Pipeline Run Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e1d27",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Healthcare Data\n",
    "\n",
    "Creating realistic synthetic data that mirrors real healthcare scenarios while being HIPAA-compliant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic patient data (EHR Source)\n",
    "def generate_patient_data(n_patients=50000):\n",
    "    \"\"\"\n",
    "    Generate synthetic patient demographics mimicking EHR system exports.\n",
    "    Includes realistic distributions for age, gender, insurance, etc.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ¥ Generating {n_patients:,} synthetic patient records...\")\n",
    "    \n",
    "    patients = []\n",
    "    for i in range(n_patients):\n",
    "        # Generate patient demographics\n",
    "        gender = np.random.choice(['M', 'F', 'Other'], p=[0.48, 0.50, 0.02])\n",
    "        birth_date = fake.date_of_birth(minimum_age=0, maximum_age=100)\n",
    "        age = (datetime.now().date() - birth_date).days // 365\n",
    "        \n",
    "        # Insurance type distribution (realistic)\n",
    "        if age >= 65:\n",
    "            insurance_type = np.random.choice(['Medicare', 'Medicare Advantage', 'Private'], \n",
    "                                             p=[0.60, 0.25, 0.15])\n",
    "        elif age < 26:\n",
    "            insurance_type = np.random.choice(['Parent Plan', 'Medicaid', 'Private', 'Uninsured'],\n",
    "                                             p=[0.40, 0.30, 0.20, 0.10])\n",
    "        else:\n",
    "            insurance_type = np.random.choice(['Private', 'Medicaid', 'Uninsured'],\n",
    "                                             p=[0.60, 0.25, 0.15])\n",
    "        \n",
    "        patient = {\n",
    "            'patient_id': f'PAT{str(i+1).zfill(8)}',\n",
    "            'medical_record_number': f'MRN{str(i+1).zfill(10)}',\n",
    "            'first_name': fake.first_name(),\n",
    "            'last_name': fake.last_name(),\n",
    "            'date_of_birth': birth_date,\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'ssn': fake.ssn(),  # PHI - will be encrypted\n",
    "            'phone': fake.phone_number(),  # PHI\n",
    "            'email': fake.email(),  # PHI\n",
    "            'address': fake.street_address(),  # PHI\n",
    "            'city': fake.city(),\n",
    "            'state': fake.state_abbr(),\n",
    "            'zip_code': fake.zipcode(),\n",
    "            'insurance_type': insurance_type,\n",
    "            'primary_care_physician': fake.name(),\n",
    "            'registration_date': fake.date_between(start_date='-10y', end_date='today'),\n",
    "            'last_visit_date': fake.date_between(start_date='-2y', end_date='today'),\n",
    "            'is_active': np.random.choice([True, False], p=[0.85, 0.15]),\n",
    "            'source_system': 'EPIC_EHR',\n",
    "            'extract_timestamp': datetime.now()\n",
    "        }\n",
    "        patients.append(patient)\n",
    "    \n",
    "    df_patients = pd.DataFrame(patients)\n",
    "    print(f\"âœ… Generated {len(df_patients):,} patient records\")\n",
    "    print(f\"   â€¢ Active patients: {df_patients['is_active'].sum():,}\")\n",
    "    print(f\"   â€¢ Average age: {df_patients['age'].mean():.1f} years\")\n",
    "    print(f\"   â€¢ Medicare patients: {(df_patients['insurance_type'].str.contains('Medicare')).sum():,}\")\n",
    "    \n",
    "    return df_patients\n",
    "\n",
    "# Generate patient data\n",
    "df_patients = generate_patient_data(50000)\n",
    "df_patients.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinical encounters data\n",
    "def generate_encounters(df_patients, avg_encounters_per_patient=3.5):\n",
    "    \"\"\"\n",
    "    Generate hospital encounters/visits with realistic diagnosis and procedure codes.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ¥ Generating clinical encounters...\")\n",
    "    \n",
    "    encounters = []\n",
    "    encounter_types = ['Emergency', 'Outpatient', 'Inpatient', 'Observation', 'Telemedicine']\n",
    "    encounter_type_probs = [0.15, 0.45, 0.20, 0.10, 0.10]\n",
    "    \n",
    "    # Common ICD-10 diagnosis codes\n",
    "    common_diagnoses = [\n",
    "        ('I10', 'Essential Hypertension'),\n",
    "        ('E11.9', 'Type 2 Diabetes Mellitus'),\n",
    "        ('J44.9', 'COPD'),\n",
    "        ('I25.10', 'Coronary Artery Disease'),\n",
    "        ('F41.9', 'Anxiety Disorder'),\n",
    "        ('M79.3', 'Chronic Pain'),\n",
    "        ('J06.9', 'Upper Respiratory Infection'),\n",
    "        ('K21.9', 'GERD'),\n",
    "        ('E78.5', 'Hyperlipidemia'),\n",
    "        ('N18.3', 'Chronic Kidney Disease')\n",
    "    ]\n",
    "    \n",
    "    for _, patient in df_patients.iterrows():\n",
    "        # Number of encounters varies by age and insurance\n",
    "        if patient['age'] > 65:\n",
    "            n_encounters = int(np.random.poisson(avg_encounters_per_patient * 2))\n",
    "        elif patient['age'] < 5:\n",
    "            n_encounters = int(np.random.poisson(avg_encounters_per_patient * 1.5))\n",
    "        else:\n",
    "            n_encounters = int(np.random.poisson(avg_encounters_per_patient))\n",
    "        \n",
    "        for _ in range(max(1, n_encounters)):\n",
    "            encounter_date = fake.date_between(\n",
    "                start_date=patient['registration_date'],\n",
    "                end_date='today'\n",
    "            )\n",
    "            \n",
    "            encounter_type = np.random.choice(encounter_types, p=encounter_type_probs)\n",
    "            \n",
    "            # Length of stay varies by encounter type\n",
    "            if encounter_type == 'Inpatient':\n",
    "                los_days = int(np.random.lognormal(1.5, 0.8))  # Average ~5 days\n",
    "            elif encounter_type == 'Observation':\n",
    "                los_days = int(np.random.uniform(1, 3))\n",
    "            else:\n",
    "                los_days = 0\n",
    "            \n",
    "            discharge_date = encounter_date + timedelta(days=los_days) if los_days > 0 else encounter_date\n",
    "            \n",
    "            # Assign diagnoses (1-3 per encounter)\n",
    "            n_diagnoses = np.random.choice([1, 2, 3], p=[0.50, 0.35, 0.15])\n",
    "            diagnoses = np.random.choice(len(common_diagnoses), n_diagnoses, replace=False)\n",
    "            primary_diagnosis = common_diagnoses[diagnoses[0]]\n",
    "            \n",
    "            encounter = {\n",
    "                'encounter_id': f'ENC{fake.uuid4()[:10].upper()}',\n",
    "                'patient_id': patient['patient_id'],\n",
    "                'encounter_type': encounter_type,\n",
    "                'admission_date': encounter_date,\n",
    "                'discharge_date': discharge_date,\n",
    "                'length_of_stay_days': los_days,\n",
    "                'primary_diagnosis_code': primary_diagnosis[0],\n",
    "                'primary_diagnosis_desc': primary_diagnosis[1],\n",
    "                'attending_physician': fake.name(),\n",
    "                'department': np.random.choice(['Cardiology', 'Endocrinology', 'Emergency', \n",
    "                                               'Primary Care', 'Pulmonology', 'Psychiatry']),\n",
    "                'discharge_disposition': np.random.choice(['Home', 'Home with Services', \n",
    "                                                          'SNF', 'Rehab', 'AMA'], \n",
    "                                                         p=[0.70, 0.15, 0.08, 0.05, 0.02]),\n",
    "                'source_system': 'EPIC_EHR',\n",
    "                'extract_timestamp': datetime.now()\n",
    "            }\n",
    "            encounters.append(encounter)\n",
    "    \n",
    "    df_encounters = pd.DataFrame(encounters)\n",
    "    print(f\"âœ… Generated {len(df_encounters):,} encounter records\")\n",
    "    print(f\"   â€¢ Average encounters per patient: {len(df_encounters) / len(df_patients):.2f}\")\n",
    "    print(f\"   â€¢ Inpatient encounters: {(df_encounters['encounter_type'] == 'Inpatient').sum():,}\")\n",
    "    print(f\"   â€¢ Average LOS (inpatient): {df_encounters[df_encounters['length_of_stay_days'] > 0]['length_of_stay_days'].mean():.1f} days\")\n",
    "    \n",
    "    return df_encounters\n",
    "\n",
    "df_encounters = generate_encounters(df_patients, avg_encounters_per_patient=3.5)\n",
    "df_encounters.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114abbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate billing/claims data\n",
    "def generate_claims(df_encounters):\n",
    "    \"\"\"\n",
    "    Generate billing claims data with charges, payments, and insurance processing.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’° Generating billing claims data...\")\n",
    "    \n",
    "    claims = []\n",
    "    \n",
    "    for _, encounter in df_encounters.iterrows():\n",
    "        # Base charge varies by encounter type\n",
    "        if encounter['encounter_type'] == 'Emergency':\n",
    "            base_charge = np.random.uniform(1500, 8000)\n",
    "        elif encounter['encounter_type'] == 'Inpatient':\n",
    "            base_charge = np.random.uniform(10000, 75000)\n",
    "        elif encounter['encounter_type'] == 'Outpatient':\n",
    "            base_charge = np.random.uniform(200, 2500)\n",
    "        elif encounter['encounter_type'] == 'Observation':\n",
    "            base_charge = np.random.uniform(3000, 12000)\n",
    "        else:  # Telemedicine\n",
    "            base_charge = np.random.uniform(50, 250)\n",
    "        \n",
    "        # Additional charges for LOS\n",
    "        total_charge = base_charge + (encounter['length_of_stay_days'] * np.random.uniform(2000, 5000))\n",
    "        \n",
    "        # Insurance payment (typically 70-90% of charges)\n",
    "        insurance_payment = total_charge * np.random.uniform(0.70, 0.90)\n",
    "        \n",
    "        # Patient responsibility\n",
    "        patient_responsibility = total_charge - insurance_payment\n",
    "        patient_payment = patient_responsibility * np.random.uniform(0.60, 0.95)  # Some unpaid\n",
    "        \n",
    "        # Claim status\n",
    "        claim_status = np.random.choice(['Paid', 'Pending', 'Denied', 'Appealed'], \n",
    "                                       p=[0.85, 0.08, 0.05, 0.02])\n",
    "        \n",
    "        claim = {\n",
    "            'claim_id': f'CLM{fake.uuid4()[:10].upper()}',\n",
    "            'encounter_id': encounter['encounter_id'],\n",
    "            'patient_id': encounter['patient_id'],\n",
    "            'claim_date': encounter['discharge_date'],\n",
    "            'total_charges': round(total_charge, 2),\n",
    "            'insurance_payment': round(insurance_payment, 2),\n",
    "            'patient_responsibility': round(patient_responsibility, 2),\n",
    "            'patient_payment': round(patient_payment, 2),\n",
    "            'outstanding_balance': round(patient_responsibility - patient_payment, 2),\n",
    "            'claim_status': claim_status,\n",
    "            'billing_provider': fake.company(),\n",
    "            'payment_date': encounter['discharge_date'] + timedelta(days=int(np.random.uniform(30, 120))),\n",
    "            'source_system': 'BILLING_DB',\n",
    "            'extract_timestamp': datetime.now()\n",
    "        }\n",
    "        claims.append(claim)\n",
    "    \n",
    "    df_claims = pd.DataFrame(claims)\n",
    "    print(f\"âœ… Generated {len(df_claims):,} billing claims\")\n",
    "    print(f\"   â€¢ Total charges: ${df_claims['total_charges'].sum():,.2f}\")\n",
    "    print(f\"   â€¢ Total insurance payments: ${df_claims['insurance_payment'].sum():,.2f}\")\n",
    "    print(f\"   â€¢ Outstanding balance: ${df_claims['outstanding_balance'].sum():,.2f}\")\n",
    "    print(f\"   â€¢ Claim denial rate: {(df_claims['claim_status'] == 'Denied').mean() * 100:.1f}%\")\n",
    "    \n",
    "    return df_claims\n",
    "\n",
    "df_claims = generate_claims(df_encounters)\n",
    "df_claims.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0518e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pharmacy/medication data\n",
    "def generate_prescriptions(df_patients, avg_meds_per_patient=2.5):\n",
    "    \"\"\"\n",
    "    Generate prescription and medication dispensing data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’Š Generating prescription data...\")\n",
    "    \n",
    "    # Common medications\n",
    "    medications = [\n",
    "        ('Lisinopril', 'Antihypertensive', 10.50),\n",
    "        ('Metformin', 'Antidiabetic', 8.25),\n",
    "        ('Atorvastatin', 'Statin', 15.75),\n",
    "        ('Omeprazole', 'PPI', 12.00),\n",
    "        ('Albuterol', 'Bronchodilator', 25.50),\n",
    "        ('Levothyroxine', 'Thyroid', 9.00),\n",
    "        ('Amlodipine', 'Calcium Channel Blocker', 11.25),\n",
    "        ('Metoprolol', 'Beta Blocker', 10.00),\n",
    "        ('Gabapentin', 'Anticonvulsant', 18.75),\n",
    "        ('Sertraline', 'SSRI', 22.50)\n",
    "    ]\n",
    "    \n",
    "    prescriptions = []\n",
    "    \n",
    "    for _, patient in df_patients.iterrows():\n",
    "        # Patients over 50 tend to have more prescriptions\n",
    "        if patient['age'] > 65:\n",
    "            n_meds = int(np.random.poisson(avg_meds_per_patient * 2))\n",
    "        elif patient['age'] > 50:\n",
    "            n_meds = int(np.random.poisson(avg_meds_per_patient * 1.5))\n",
    "        else:\n",
    "            n_meds = int(np.random.poisson(avg_meds_per_patient * 0.8))\n",
    "        \n",
    "        for _ in range(max(0, n_meds)):\n",
    "            medication = medications[np.random.randint(0, len(medications))]\n",
    "            \n",
    "            prescription_date = fake.date_between(\n",
    "                start_date=patient['registration_date'],\n",
    "                end_date='today'\n",
    "            )\n",
    "            \n",
    "            # Days supply and refills\n",
    "            days_supply = np.random.choice([30, 60, 90], p=[0.60, 0.25, 0.15])\n",
    "            refills_allowed = np.random.choice([0, 1, 2, 3, 11], p=[0.10, 0.20, 0.30, 0.25, 0.15])\n",
    "            refills_remaining = np.random.randint(0, refills_allowed + 1)\n",
    "            \n",
    "            prescription = {\n",
    "                'prescription_id': f'RX{fake.uuid4()[:10].upper()}',\n",
    "                'patient_id': patient['patient_id'],\n",
    "                'medication_name': medication[0],\n",
    "                'medication_class': medication[1],\n",
    "                'prescribing_physician': fake.name(),\n",
    "                'prescription_date': prescription_date,\n",
    "                'fill_date': prescription_date + timedelta(days=np.random.randint(0, 7)),\n",
    "                'days_supply': days_supply,\n",
    "                'quantity': np.random.randint(30, 180),\n",
    "                'refills_allowed': refills_allowed,\n",
    "                'refills_remaining': refills_remaining,\n",
    "                'pharmacy_name': np.random.choice(['CVS', 'Walgreens', 'Walmart', 'Kroger', 'Local Pharmacy']),\n",
    "                'cost': round(medication[2] * (days_supply / 30), 2),\n",
    "                'copay': round(np.random.uniform(5, 50), 2),\n",
    "                'is_generic': np.random.choice([True, False], p=[0.85, 0.15]),\n",
    "                'source_system': 'PHARMACY_API',\n",
    "                'extract_timestamp': datetime.now()\n",
    "            }\n",
    "            prescriptions.append(prescription)\n",
    "    \n",
    "    df_prescriptions = pd.DataFrame(prescriptions)\n",
    "    print(f\"âœ… Generated {len(df_prescriptions):,} prescription records\")\n",
    "    print(f\"   â€¢ Average prescriptions per patient: {len(df_prescriptions) / len(df_patients):.2f}\")\n",
    "    print(f\"   â€¢ Generic medication rate: {df_prescriptions['is_generic'].mean() * 100:.1f}%\")\n",
    "    print(f\"   â€¢ Total medication cost: ${df_prescriptions['cost'].sum():,.2f}\")\n",
    "    \n",
    "    return df_prescriptions\n",
    "\n",
    "df_prescriptions = generate_prescriptions(df_patients, avg_meds_per_patient=2.5)\n",
    "df_prescriptions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af42d5",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment (Pre-ETL)\n",
    "\n",
    "Before loading data, we perform comprehensive quality checks to identify:\n",
    "- Missing critical fields\n",
    "- Data type mismatches\n",
    "- Duplicate records\n",
    "- Referential integrity issues\n",
    "- Outliers and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8881411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Framework\n",
    "def assess_data_quality(df, table_name, critical_columns):\n",
    "    \"\"\"\n",
    "    Comprehensive data quality assessment with detailed reporting.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ” Data Quality Assessment: {table_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    quality_report = {\n",
    "        'table_name': table_name,\n",
    "        'total_records': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'assessment_date': datetime.now(),\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # 1. Completeness Check\n",
    "    print(\"\\nðŸ“Š Completeness Analysis:\")\n",
    "    missing_summary = df.isnull().sum()\n",
    "    missing_pct = (missing_summary / len(df) * 100).round(2)\n",
    "    \n",
    "    for col in critical_columns:\n",
    "        if col in df.columns:\n",
    "            missing_count = missing_summary[col]\n",
    "            if missing_count > 0:\n",
    "                issue = f\"Critical column '{col}' has {missing_count} ({missing_pct[col]}%) missing values\"\n",
    "                quality_report['issues'].append(issue)\n",
    "                print(f\"   âš ï¸  {issue}\")\n",
    "            else:\n",
    "                print(f\"   âœ… {col}: 100% complete\")\n",
    "    \n",
    "    # 2. Duplicate Check\n",
    "    print(\"\\nðŸ”„ Duplicate Analysis:\")\n",
    "    if 'patient_id' in df.columns:\n",
    "        duplicates = df['patient_id'].duplicated().sum()\n",
    "        if duplicates > 0:\n",
    "            issue = f\"Found {duplicates} duplicate patient_id records\"\n",
    "            quality_report['issues'].append(issue)\n",
    "            print(f\"   âš ï¸  {issue}\")\n",
    "        else:\n",
    "            print(f\"   âœ… No duplicate patient_id found\")\n",
    "    \n",
    "    # 3. Data Type Validation\n",
    "    print(\"\\nðŸ“ Data Type Validation:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    # 4. Statistical Summary\n",
    "    print(\"\\nðŸ“ˆ Statistical Summary:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(df[numeric_cols].describe().round(2))\n",
    "    \n",
    "    # 5. Overall Quality Score\n",
    "    completeness_score = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "    duplicate_score = (1 - (duplicates / len(df) if 'patient_id' in df.columns else 0)) * 100\n",
    "    overall_score = (completeness_score + duplicate_score) / 2\n",
    "    \n",
    "    quality_report['completeness_score'] = round(completeness_score, 2)\n",
    "    quality_report['overall_quality_score'] = round(overall_score, 2)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Quality Score: {overall_score:.1f}%\")\n",
    "    print(f\"   â€¢ Completeness: {completeness_score:.1f}%\")\n",
    "    print(f\"   â€¢ Uniqueness: {duplicate_score:.1f}%\")\n",
    "    \n",
    "    if len(quality_report['issues']) == 0:\n",
    "        print(\"\\nâœ… No critical issues found!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  {len(quality_report['issues'])} issue(s) identified\")\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Assess quality for each dataset\n",
    "quality_patients = assess_data_quality(\n",
    "    df_patients, \n",
    "    'PATIENTS', \n",
    "    ['patient_id', 'medical_record_number', 'date_of_birth', 'gender']\n",
    ")\n",
    "\n",
    "quality_encounters = assess_data_quality(\n",
    "    df_encounters,\n",
    "    'ENCOUNTERS',\n",
    "    ['encounter_id', 'patient_id', 'admission_date', 'encounter_type']\n",
    ")\n",
    "\n",
    "quality_claims = assess_data_quality(\n",
    "    df_claims,\n",
    "    'CLAIMS',\n",
    "    ['claim_id', 'encounter_id', 'patient_id', 'total_charges']\n",
    ")\n",
    "\n",
    "quality_prescriptions = assess_data_quality(\n",
    "    df_prescriptions,\n",
    "    'PRESCRIPTIONS',\n",
    "    ['prescription_id', 'patient_id', 'medication_name', 'prescription_date']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e4c34",
   "metadata": {},
   "source": [
    "## 4. HIPAA Compliance & PHI Encryption\n",
    "\n",
    "Implementing HIPAA-compliant data handling:\n",
    "- **PHI Encryption:** Hash SSN, mask phone/email\n",
    "- **De-identification:** Create anonymous identifiers\n",
    "- **Audit Logging:** Track all data access\n",
    "- **Access Control:** Role-based security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29120b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIPAA Compliance Functions\n",
    "def hash_phi(value):\n",
    "    \"\"\"\n",
    "    One-way hash for PHI fields (SSN, etc.) using SHA-256.\n",
    "    In production, use AWS KMS or similar encryption service.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    return hashlib.sha256(str(value).encode()).hexdigest()\n",
    "\n",
    "def mask_phone(phone):\n",
    "    \"\"\"\n",
    "    Mask phone number: (555) 123-4567 -> (XXX) XXX-4567\n",
    "    \"\"\"\n",
    "    if pd.isna(phone):\n",
    "        return None\n",
    "    # Keep last 4 digits only\n",
    "    cleaned = re.sub(r'\\D', '', phone)\n",
    "    if len(cleaned) >= 4:\n",
    "        return 'XXX-XXX-' + cleaned[-4:]\n",
    "    return 'XXX-XXX-XXXX'\n",
    "\n",
    "def mask_email(email):\n",
    "    \"\"\"\n",
    "    Mask email: john.doe@example.com -> j***e@example.com\n",
    "    \"\"\"\n",
    "    if pd.isna(email):\n",
    "        return None\n",
    "    parts = email.split('@')\n",
    "    if len(parts) == 2:\n",
    "        username = parts[0]\n",
    "        if len(username) > 2:\n",
    "            return f\"{username[0]}{'*' * (len(username)-2)}{username[-1]}@{parts[1]}\"\n",
    "    return 'masked@domain.com'\n",
    "\n",
    "def create_deidentified_id(patient_id, salt='HEALTHCARE_DW_2025'):\n",
    "    \"\"\"\n",
    "    Create consistent de-identified patient ID for analytics.\n",
    "    \"\"\"\n",
    "    combined = f\"{patient_id}_{salt}\"\n",
    "    hashed = hashlib.sha256(combined.encode()).hexdigest()[:16]\n",
    "    return f\"DEID_{hashed.upper()}\"\n",
    "\n",
    "# Apply HIPAA transformations\n",
    "def apply_hipaa_compliance(df_patients):\n",
    "    \"\"\"\n",
    "    Apply HIPAA-compliant transformations to patient data.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ”’ Applying HIPAA Compliance Transformations...\")\n",
    "    \n",
    "    df_secure = df_patients.copy()\n",
    "    \n",
    "    # Create de-identified patient ID\n",
    "    df_secure['deidentified_patient_id'] = df_secure['patient_id'].apply(create_deidentified_id)\n",
    "    \n",
    "    # Hash SSN (one-way encryption)\n",
    "    df_secure['ssn_hash'] = df_secure['ssn'].apply(hash_phi)\n",
    "    df_secure = df_secure.drop('ssn', axis=1)\n",
    "    \n",
    "    # Mask phone and email\n",
    "    df_secure['phone_masked'] = df_secure['phone'].apply(mask_phone)\n",
    "    df_secure['email_masked'] = df_secure['email'].apply(mask_email)\n",
    "    df_secure = df_secure.drop(['phone', 'email'], axis=1)\n",
    "    \n",
    "    # Generalize address to ZIP code only for analytics\n",
    "    df_secure['address_city_state'] = df_secure['city'] + ', ' + df_secure['state']\n",
    "    df_secure = df_secure.drop(['address', 'city', 'state'], axis=1)\n",
    "    \n",
    "    # Add compliance metadata\n",
    "    df_secure['phi_encrypted_date'] = datetime.now()\n",
    "    df_secure['compliance_version'] = 'HIPAA_2024_v1'\n",
    "    \n",
    "    print(\"âœ… HIPAA compliance applied:\")\n",
    "    print(f\"   â€¢ SSN: Hashed (SHA-256)\")\n",
    "    print(f\"   â€¢ Phone: Masked (last 4 digits only)\")\n",
    "    print(f\"   â€¢ Email: Masked\")\n",
    "    print(f\"   â€¢ Address: Generalized to city/state\")\n",
    "    print(f\"   â€¢ De-identified ID created for {len(df_secure):,} patients\")\n",
    "    \n",
    "    return df_secure\n",
    "\n",
    "# Apply compliance transformations\n",
    "df_patients_secure = apply_hipaa_compliance(df_patients)\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\nðŸ“‹ Before HIPAA Compliance:\")\n",
    "print(df_patients[['patient_id', 'first_name', 'last_name', 'ssn', 'phone', 'email', 'address']].head(2))\n",
    "\n",
    "print(\"\\nðŸ”’ After HIPAA Compliance:\")\n",
    "print(df_patients_secure[['patient_id', 'deidentified_patient_id', 'first_name', 'last_name', \n",
    "                          'ssn_hash', 'phone_masked', 'email_masked', 'address_city_state']].head(2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
